{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25bff69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PointDetection_CPU'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# import cupy as cp\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# cp.array(0)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# import PointDetection_peak as cd\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# cp.array(0)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPointDetection_CPU\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'PointDetection_CPU'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ants\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import os\n",
    "# import cv2\n",
    "import csv\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.ndimage import zoom\n",
    "import scipy.ndimage as ndi\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from multiprocessing import Pool\n",
    "plt.gray()\n",
    "\n",
    "import json, os.path, os, re, time\n",
    "import joblib\n",
    "import subprocess as sp\n",
    "import nibabel as nib\n",
    "import scipy.spatial\n",
    "import cupy as cp\n",
    "import cupyx.scipy.ndimage as ndi\n",
    "# cp.array(0)\n",
    "import PointDetection as cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ff9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56960a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_filter_GPU(img_o, sigma):\n",
    "    img = cp.asarray(img_o)\n",
    "    dst=cpn.gaussian_filter(img,sigma=sigma, mode=\"reflect\")\n",
    "    dst2=cp.asnumpy(dst)\n",
    "    del img\n",
    "    del dst\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    return dst2\n",
    "\n",
    "def min_max(x:np.ndarray):\n",
    "    minval = x.min(axis=None, keepdims=True)\n",
    "    maxval= x.max(axis=None, keepdims=True)\n",
    "    result = (x-minval)/(maxval-minval)\n",
    "    return result    \n",
    "    \n",
    "def make_psf(size, sigma):\n",
    "    p = np.zeros((size, size, size))\n",
    "    p[size//2, size//2, size//2] = 1\n",
    "    p = ndimage.gaussian_filter(p, sigma)\n",
    "    p /= p.sum()\n",
    "    return p\n",
    "    \n",
    "def LR_deconv(img,psf,i):\n",
    "    im=img.copy()\n",
    "    for n in range(i):\n",
    "        print(n)\n",
    "        normalize_and_convert_to_float(im)\n",
    "        im1=im.copy()\n",
    "        conv1=img/ndimage.convolve(im1, psf, mode='constant', cval=0.0)\n",
    "        conv2=ndimage.convolve(conv1, psf, mode='constant', cval=0.0)\n",
    "        im=im1*conv2 \n",
    "    return im\n",
    "\n",
    "def normalize_and_convert_to_float(array):\n",
    "    float_array = array.astype(np.float32)\n",
    "    min_val = float_array.min()\n",
    "    max_val = float_array.max()\n",
    "    normalized_array = (float_array - min_val) / (max_val - min_val)\n",
    "    return normalized_array\n",
    "\n",
    "   \n",
    "def LR_deconv_GPU(img, psf, i, zval=40, overlap=10,zoom=(2.5, 2.5, 2.5)):\n",
    "    psf=normalize_and_convert_to_float(psf)\n",
    "    psf_cp =  cp.asarray(psf).astype(cp.float32)   \n",
    "    im = img.astype(cp.float32)\n",
    "    result = np.empty_like(im)\n",
    "    for start_z in range(0, im.shape[0], zval - overlap):\n",
    "        print(\"\\tProcess deconvolution:\"+str(start_z))\n",
    "        end_z = min(start_z + zval, im.shape[0])\n",
    "        im_chunk =im[start_z:end_z]\n",
    "        im_chunk_gpu=cp.asarray(im_chunk).astype(cp.float32)\n",
    "        im_chunk_gpu_d=im_chunk_gpu.copy()\n",
    "        for n in range(i):\n",
    "            conv1 = cp.divide(im_chunk_gpu_d, ndi.convolve(im_chunk_gpu, psf_cp, mode='constant', cval=0.0))#\n",
    "            conv2 = ndi.convolve(conv1, psf_cp, mode='constant', cval=0.0)#\n",
    "            if(n!=(i-1)):\n",
    "                im_chunk_gpu *= conv2#u(t+1)\n",
    "        if start_z==0:\n",
    "            result[start_z:end_z] = cp.asnumpy(im_chunk_gpu)\n",
    "        else:\n",
    "            result[start_z+overlap//2:end_z] = cp.asnumpy(im_chunk_gpu[overlap//2:])\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def read_tiff_stack(folder_path, start_index=0, num_images=-1):\n",
    "    # Get the list of TIFF files\n",
    "    \n",
    "    tiff_files = [os.path.join(folder_path, filename)\n",
    "                  for filename in os.listdir(folder_path)\n",
    "                  if filename.lower().endswith(('.tif', '.tiff'))]\n",
    "    # Sort the files to ensure correct order\n",
    "    tiff_files.sort()\n",
    "\n",
    "    # Select the specified range of files\n",
    "    if num_images == -1:\n",
    "        tiff_files = tiff_files[start_index:]\n",
    "    else:\n",
    "        tiff_files = tiff_files[start_index:(start_index + num_images)]\n",
    "    print(\"Load tiff:\" + str(start_index) + \"-\" + str(len(tiff_files)))\n",
    "    first_tiff = tifffile.imread(tiff_files[0])\n",
    "    shape = (len(tiff_files),) + first_tiff.shape\n",
    "    stack = np.empty(shape, dtype=np.uint16)\n",
    "\n",
    "    # Read each TIFF file and store it in the stack\n",
    "    for i, tiff_file in enumerate(tiff_files):\n",
    "        stack[i] = tifffile.imread(tiff_file)\n",
    "\n",
    "    return stack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf17415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "72\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "# cfos_fol=\"/home/gpu_data/data1/yamashitaData1/231012_circadian_2nd_Data1/231012_circadian_2nd_Reconst/\"\n",
    "# exp = \"2nd\"\n",
    "cfos_fol=\"/home/gpu_data/data1/yamashitaData1/230828circadian_Data1/230828circadian_1st_Reconst/\"\n",
    "exp = \"1st\"\n",
    "savedir = \"/home/gpu_data/data8/cfos_app/\"\n",
    "Resize_um = 50\n",
    "\n",
    "CT_li = np.arange(0,48,4)\n",
    "sample_ids = np.arange(1,7,1)\n",
    "\n",
    "reconsts = os.listdir(cfos_fol)\n",
    "sample_names=[]\n",
    "colors=[]\n",
    "data_parent_paths=[]\n",
    "data_moving_paths =[]\n",
    "\n",
    "for CT in CT_li:\n",
    "#     if CT>72:\n",
    "#         continue\n",
    "    for sample_id in sample_ids:\n",
    "        sample = \"CT\"+str(CT)+\"_\"+str(sample_id).zfill(2)\n",
    "\n",
    "        for reconst in reconsts:\n",
    "#             sample_names.append((\"_\").join(reconst.split(\"_\")[1:3]))\n",
    "\n",
    "            if sample in reconst:\n",
    "                sample_names.append(sample)\n",
    "                for color in os.listdir(cfos_fol+reconst):\n",
    "                    if \"cfos\" in color:\n",
    "                        data_moving_paths.append(cfos_fol+reconst+\"/\"+color)\n",
    "                    else:\n",
    "                        data_parent_paths.append(cfos_fol+reconst+\"/\"+color)\n",
    "\n",
    "print(len(data_parent_paths))   \n",
    "print(len(data_moving_paths))\n",
    "print(len(sample_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4031660-0b0c-4f14-bfb5-e08b8afad55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deconvolution\n",
    "\n",
    "src =\"/home/gpu_data/data7/\"\n",
    "dst = \"/home/gpu_data/data8/results/\"\n",
    "pre_img_path = src+\"/yamashita/202404_WT_SD_DD/\" \n",
    "deconv_path = src +\"/yamashita/202404_WT_SD_DD/deconv/\" \n",
    "color_name = \"cFos\"      # Input directory name for the 1st color\n",
    "os.makedirs(deconv_path, exist_ok=True)\n",
    "\n",
    "psf=make_psf(9, (1.8,1.8,1.8))\n",
    "z_chunk=100\n",
    "\n",
    "c = 0\n",
    "for fol in os.listdir(pre_img_path):\n",
    "    if \"CT0\" in fol:\n",
    "        continue\n",
    "    if \"Reconst\" in fol:\n",
    "        c += 1\n",
    "        if c < 2:\n",
    "            continue\n",
    "        print(fol)\n",
    "        for fol2 in os.listdir(pre_img_path + fol):\n",
    "            if \"cfos\" in fol2:\n",
    "                FPr = pre_img_path + fol +\"/\" + fol2\n",
    "                FPw = deconv_path + fol +\"/\" + fol2\n",
    "                if os.path.exists(FPw):\n",
    "                    continue\n",
    "                os.makedirs(FPw, exist_ok=True)\n",
    "                \n",
    "                \n",
    "                \n",
    "                zoom_factors=(2.5, 2.5, 2.5)\n",
    "                overlap =psf.shape[0]+7\n",
    "                overlap_zoom = int((psf.shape[0]) * 2)  # Adjust overlap based on zoom factor\n",
    "                im = read_tiff_stack(FPr)\n",
    "                im[im<1000]=1000\n",
    "                os.makedirs(FPw, exist_ok=True)\n",
    "                for start_z in range(0, im.shape[0], z_chunk - overlap // 2):\n",
    "                    \n",
    "                    print(\"Process z:\" + str(start_z))\n",
    "                    end_z = min(start_z + z_chunk, im.shape[0])\n",
    "                    im2 = cp.asnumpy(cpx_ndimage.zoom(cp.asarray(im[start_z:end_z] // 2), zoom=zoom_factors, order=3))\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    RC = LR_deconv_GPU(im2, psf, 10, zval=40, overlap=overlap_zoom)\n",
    "                    del im2\n",
    "                    gc.collect()\n",
    "                    cp.get_default_memory_pool().free_all_blocks()\n",
    "                    RC = np.clip(RC * 2, 0, 65535).astype(np.uint16)\n",
    "                    \n",
    "                    for i, z_slice in enumerate(RC):\n",
    "                        if start_z != 0 and i < overlap // 2:\n",
    "                            continue\n",
    "                        filename = f\"{int(start_z*zoom_factors[0]+i):08d}.tif\"\n",
    "                        tifffile.imwrite(os.path.join(FPw, filename), z_slice)\n",
    "                    del RC \n",
    "                    gc.collect()\n",
    "                del im\n",
    "                gc.collect()\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0155eb-0496-4568-b2e6-8900063fc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect cell candidates by intensity peaks\n",
    "src = \"/home/gpu_data/data1/\"\n",
    "dst = \"/home/gpu_data/data7/\"\n",
    "root = src+\"yamashitaData1/\"\n",
    "\n",
    "deconv_fs = [\"230828circadian_Data1/230828circadian_1st_Reconst_median_norm_Deconv\", \"231012_circadian_2nd_Data1/231012_circadian_2nd_Reconst_median_norm_Deconv\"]\n",
    "postfix = \"output_peak\"\n",
    "# FP = root+\"/230828circadian_1st_Reconst_median_norm_Deconv\"    # Input directory path for the parent folder\n",
    "# FPout = root+\"/cfos_1st_median_norm_Deconv_output\"  # Input directory path for the output parent folder\n",
    "\n",
    "structure_name = \"SYTOX-G\"  # Input directory name for structure image\n",
    "color_name1 = \"cfos\"      # Input directory name for the 1st color\n",
    "resolution = int(10/2.5)             # Input voxel size in micrometers (μm)\n",
    "\n",
    "params=[5000, 0, 2500, -1]  #\n",
    "peak_size = 7  #3\n",
    "psf_sizes =  [13, 27] #[5, 11]\n",
    "psf_sigmas = [(1,1,1), (2,1,1)]\n",
    "line_sizes = [13, 25, 51]  #[5, 11, 23]\n",
    "line_3d_sigmas = [(1.5,1.5,1.5)]\n",
    "batchsize=100\n",
    "overlap=10\n",
    "threads=20\n",
    "dirs=[]\n",
    "cellnumber=[]\n",
    "skip=1\n",
    "\n",
    "for i, deconv_f in enumerate(deconv_fs):\n",
    "    if i>0:\n",
    "        continue\n",
    "    \n",
    "    FP = root+deconv_f    # Input directory path for the parent folder\n",
    "    FPout =dst+deconv_f +\"_\"+postfix  # Input directory path for the output parent folder\n",
    "\n",
    "\n",
    "    for d in os.listdir(FP):\n",
    "        if(os.path.isdir(FP+\"/\"+d)):\n",
    "            dirs.append(d)\n",
    "\n",
    "\n",
    "\n",
    "    for dir in dirs:\n",
    "#         if \"CT0_01\" in dir or \"CT8_01\" in dir or \"CT16_01\" in dir:\n",
    "            if os.path.exists(FPout+\"/\"+dir+\"/coordinates.csv\"):\n",
    "                print(\"{} already exist\".format(FPout+\"/\"+dir+\"/coordinates.csv\"))\n",
    "                continue\n",
    "            print(FP+\"/\"+dir)\n",
    "        #     sample_name = \"CT0_01\"\n",
    "        #     if(sample_name in dir):\n",
    "        #         skip=0\n",
    "        #     if(skip==1):\n",
    "        #         continue\n",
    "            if(color_name1 in dir):\n",
    "                FPr=FP+\"/\"+dir\n",
    "                FPw=FPout+\"/\"+dir\n",
    "                df=cd.GetCells(FPr, FPw, params, peak_size, psf_sizes, psf_sigmas, line_sizes, line_3d_sigmas, batchsize, overlap, threads)\n",
    "                cellnumber.append((dir,str(len(df))))\n",
    "#         skip=1\n",
    "# with open(FPout+\"/result.csv\", \"a\", newline=\"\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(cellnumber)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca8532a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cell detect only peak deconv pre\n",
    "src = \"/home/gpu_data/data1/\"\n",
    "dst = \"/home/gpu_data/data7/\"\n",
    "root = src+\"yamashitaData1/\"\n",
    "\n",
    "deconv_fs = [\"230828circadian_Data1/230828circadian_1st_Reconst_median_norm_Deconv\", \"231012_circadian_2nd_Data1/231012_circadian_2nd_Reconst_median_norm_Deconv\"]\n",
    "postfix = \"output_peak_2500\"\n",
    "# FP = root+\"/230828circadian_1st_Reconst_median_norm_Deconv\"    # Input directory path for the parent folder\n",
    "# FPout = root+\"/cfos_1st_median_norm_Deconv_output\"  # Input directory path for the output parent folder\n",
    "FP_PSF = src + \"/matsumoto/CUBIC/spf\"  # Input directory path to store PSF data\n",
    "structure_name = \"SYTOX-G\"  # Input directory name for structure image\n",
    "color_name1 = \"cfos\"      # Input directory name for the 1st color\n",
    "resolution = int(10/2.5)             # Input voxel size in micrometers (μm)\n",
    "\n",
    "params=[5000, 2500, 8.0, 1.5]\n",
    "peak_size = 3\n",
    "psf_sizes = [5, 11]\n",
    "psf_sigmas = [(1,1,1), (2,1,1)]\n",
    "line_sizes = [5, 11, 23]\n",
    "line_3d_sigmas = [(1.5,1.5,1.5)]\n",
    "batchsize=200\n",
    "overlap=10\n",
    "threads=15\n",
    "dirs=[]\n",
    "cellnumber=[]\n",
    "skip=1\n",
    "\n",
    "# for i, deconv_f in enumerate(deconv_fs):\n",
    "#     if i>0:\n",
    "#         continue\n",
    "    \n",
    "#     FP = root+deconv_f    # Input directory path for the parent folder\n",
    "    \n",
    "FPout =dst+ \"/test_getcell_th\" +\"_\"+postfix  # Input directory path for the output parent folder\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FP = src+\"/yamashitaData1/230828circadian_Data1/230828circadian_1st_Reconst/0066_CT0_01_Reconst/cfos_CT0_01'\"\n",
    "\n",
    "#     for dir in dirs:\n",
    "#         if \"CT0_01\" in dir or \"CT8_01\" in dir or \"CT16_01\" in dir:\n",
    "\n",
    "#             print(FP+\"/\"+dir)\n",
    "    #     sample_name = \"CT0_01\"\n",
    "    #     if(sample_name in dir):\n",
    "    #         skip=0\n",
    "    #     if(skip==1):\n",
    "    #         continue\n",
    "\n",
    "FPr=FP\n",
    "FPw=FPout\n",
    "df=cd.GetCells(FPr, FPw, params, peak_size, psf_sizes, psf_sigmas, line_sizes, line_3d_sigmas, batchsize, overlap, threads)\n",
    "#             cellnumber.append((dir,str(len(df))))\n",
    "#         skip=1\n",
    "# with open(FPout+\"/result.csv\", \"a\", newline=\"\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(cellnumber)\n",
    "        #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
